{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e3bcc1-f2dd-4b82-9a1f-486869cbd501",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "- **Role**: Strategist at a leading e-commerce company.\n",
    "\n",
    "- **Task**: Prepare for the upcoming festive season by analyzing competitors' discounts and promotional offers.\n",
    "\n",
    "- **Objective**: Design a competitive strategy to either match or surpass the competition's offers.\n",
    "\n",
    "- **Solution**: Develop an **Agentic System** with the following features:\n",
    "  - **Dynamic Coding**: Ability to adapt to changes in website structure.\n",
    "  - **Web Scraping**: Targeted extraction of discounts and promotional offers from competitor platforms.\n",
    "  - **Data Summarization**: Process and organize extracted information for actionable insights.\n",
    "\n",
    "- **Outcome**: Enable data-driven decision-making to ensure a competitive edge during the festive season.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d626c-7884-4e04-a994-368ae18e888f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e57bf01-3307-42c0-b117-fdcc4a04ddb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ag2course/lib/python3.13/site-packages/flaml/__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "from autogen import ConversableAgent, AssistantAgent, UserProxyAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e781680b-fa3b-416e-8e41-4f3afa96e394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('/Users/admin/Desktop/AutoGen/Module 1/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb6d90-eef7-4eb6-8d78-bc87c6eacc25",
   "metadata": {},
   "source": [
    "# Local Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698f3cdc-267b-4b91-9567-66138f00727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f49869-3d67-4275-8361-b5edf9f2bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_writer_agent = ConversableAgent(\n",
    "    name=\"CodeWriter\",\n",
    "    system_message=\"\"\"You are a Python developer.\n",
    "    You use your coding skill to solve problems.\n",
    "    Once the task is done, returns 'TERMINATE'.\"\"\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\"}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64cf50c8-df98-4cfa-84f2-1f030a03b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_reviewer_agent = ConversableAgent(\n",
    "    name=\"CodeReviewer\",\n",
    "    system_message=\"\"\"You are an experienced software developer\n",
    "    Review the code given to you based on the requirements\n",
    "    Once the task is done, returns 'TERMINATE'.\"\"\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\"}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cce19a-ce20-4b49-ac3f-250cc076d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=20,\n",
    "    work_dir='./code files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d37b009-74e7-499b-b382-de1a731aaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_executor_agent = ConversableAgent(\n",
    "    \"local_executor_agent\",\n",
    "    llm_config=False, \n",
    "    code_execution_config={\"executor\": local_executor},\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b31f1-3140-448e-860b-5fc2a0ec2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\"\"\"To check whether there are any offers or discounts available on a given e-commerce website -\n",
    "                https://www.flipkart.com/\n",
    "                Follow these steps,\n",
    "                1. download the html page of the given URL\n",
    "                2. we only need text content, so remove any CSS, JavaScript, and Image content\n",
    "                3. save the remaining html content.\n",
    "               \"\"\" ,\n",
    "    \"\"\"The code is given by an LLM. Review the code based on the above requirements and provide it for execution\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df70c456-ab38-4885-a5fb-60499bfea323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to CodeWriter):\n",
      "\n",
      "To check whether there are any offers or discounts available on a given e-commerce website -\n",
      "                https://www.flipkart.com/\n",
      "                Follow these steps,\n",
      "                1. download the html page of the given URL\n",
      "                2. we only need text content, so remove any CSS, JavaScript, and Image content\n",
      "                3. save the remaining html content.\n",
      "               \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeWriter\u001b[0m (to User):\n",
      "\n",
      "To achieve this task, we can use Python with the `requests` library to download the HTML content and `BeautifulSoup` from the `bs4` library to parse and clean the HTML. We'll focus on extracting only the text content.\n",
      "\n",
      "Here is a complete code snippet to perform the steps described:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Step 1: Download the HTML page of the given URL\n",
      "url = \"https://www.flipkart.com/\"\n",
      "response = requests.get(url)\n",
      "\n",
      "# Check if the request was successful\n",
      "if response.status_code == 200:\n",
      "    html_content = response.text\n",
      "    \n",
      "    # Step 2: Remove CSS, JavaScript, and Image content\n",
      "    soup = BeautifulSoup(html_content, 'html.parser')\n",
      "    \n",
      "    # Remove all style and script tags\n",
      "    for script in soup(['script', 'style', 'img']):\n",
      "        script.decompose()\n",
      "    \n",
      "    # Get text content\n",
      "    text_content = soup.get_text(separator='\\n', strip=True)\n",
      "    \n",
      "    # Step 3: Save the remaining HTML content to a file\n",
      "    with open('flipkart_text_content.txt', 'w', encoding='utf-8') as file:\n",
      "        file.write(text_content)\n",
      "\n",
      "    print(\"Content saved to 'flipkart_text_content.txt'\")\n",
      "else:\n",
      "    print(\"Failed to retrieve the webpage.\")\n",
      "\n",
      "# To indicate that the task is completed\n",
      "\"TERMINATE\"\n",
      "```\n",
      "\n",
      "### Instructions to run the script:\n",
      "1. Ensure you have `requests` and `beautifulsoup4` installed. You can install them via pip if you haven't:\n",
      "   ```bash\n",
      "   pip install requests beautifulsoup4\n",
      "   ```\n",
      "2. Run the script in a Python environment.\n",
      "\n",
      "This code will download the HTML page, clean it by removing any CSS, JavaScript, and image content, and save the remaining text content to a file named `flipkart_text_content.txt`. \n",
      "\n",
      "Once completed, it will print a message confirming that the content has been saved, and you'll see 'TERMINATE' indicating the end of the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give feedback to CodeWriter. Press enter or type 'exit' to stop the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mlocal_executor_agent\u001b[0m (to CodeReviewer):\n",
      "\n",
      "To check whether there are any offers or discounts available on a given e-commerce website -\n",
      "                https://www.flipkart.com/\n",
      "                Follow these steps,\n",
      "                1. download the html page of the given URL\n",
      "                2. we only need text content, so remove any CSS, JavaScript, and Image content\n",
      "                3. save the remaining html content.\n",
      "               The code is given by an LLM. Review the code based on the above requirements and provide it for execution\n",
      "Context: \n",
      "To achieve this task, we can use Python with the `requests` library to download the HTML content and `BeautifulSoup` from the `bs4` library to parse and clean the HTML. We'll focus on extracting only the text content.\n",
      "\n",
      "Here is a complete code snippet to perform the steps described:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Step 1: Download the HTML page of the given URL\n",
      "url = \"https://www.flipkart.com/\"\n",
      "response = requests.get(url)\n",
      "\n",
      "# Check if the request was successful\n",
      "if response.status_code == 200:\n",
      "    html_content = response.text\n",
      "    \n",
      "    # Step 2: Remove CSS, JavaScript, and Image content\n",
      "    soup = BeautifulSoup(html_content, 'html.parser')\n",
      "    \n",
      "    # Remove all style and script tags\n",
      "    for script in soup(['script', 'style', 'img']):\n",
      "        script.decompose()\n",
      "    \n",
      "    # Get text content\n",
      "    text_content = soup.get_text(separator='\\n', strip=True)\n",
      "    \n",
      "    # Step 3: Save the remaining HTML content to a file\n",
      "    with open('flipkart_text_content.txt', 'w', encoding='utf-8') as file:\n",
      "        file.write(text_content)\n",
      "\n",
      "    print(\"Content saved to 'flipkart_text_content.txt'\")\n",
      "else:\n",
      "    print(\"Failed to retrieve the webpage.\")\n",
      "\n",
      "# To indicate that the task is completed\n",
      "\"\"\n",
      "```\n",
      "\n",
      "### Instructions to run the script:\n",
      "1. Ensure you have `requests` and `beautifulsoup4` installed. You can install them via pip if you haven't:\n",
      "   ```bash\n",
      "   pip install requests beautifulsoup4\n",
      "   ```\n",
      "2. Run the script in a Python environment.\n",
      "\n",
      "This code will download the HTML page, clean it by removing any CSS, JavaScript, and image content, and save the remaining text content to a file named `flipkart_text_content.txt`. \n",
      "\n",
      "Once completed, it will print a message confirming that the content has been saved, and you'll see '' indicating the end of the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeReviewer\u001b[0m (to local_executor_agent):\n",
      "\n",
      "The provided code meets the requirements outlined for checking offers or discounts available on the given e-commerce website (Flipkart). Below is the review of the code based on the provided steps:\n",
      "\n",
      "### Code Review\n",
      "\n",
      "1. **Downloading HTML Page**: \n",
      "   - The use of the `requests.get(url)` method correctly retrieves the HTML content from the specified URL. It also checks the HTTP response status to ensure the request was successful.\n",
      "\n",
      "2. **Parsing the HTML and Cleaning Content**:\n",
      "   - `BeautifulSoup` is used to parse the HTML content effectively.\n",
      "   - The removal of `<script>`, `<style>`, and `<img>` tags is done using the `decompose()` method, which is the correct approach to clean the HTML content.\n",
      "\n",
      "3. **Extracting Text Content**:\n",
      "   - The `get_text(separator='\\n', strip=True)` method is appropriately used to extract the text, ensuring that it is well-formatted and unnecessary whitespace is removed.\n",
      "\n",
      "4. **Saving Remaining HTML Content**:\n",
      "   - The remaining text content is saved to a text file named `flipkart_text_content.txt`, which is in line with the requirement to save the processed content.\n",
      "\n",
      "5. **Output Confirmation**:\n",
      "   - A print statement confirms the successful saving of content, enhancing user experience.\n",
      "\n",
      "### Areas of Improvement:\n",
      "- The script could benefit from error handling beyond just checking the status code. For instance, it might be worthwhile to handle exceptions that could arise during the request (e.g., network issues) and during file writing (e.g., permissions issues).\n",
      "- The output confirmation could include the path to the saved file for better user clarity.\n",
      "\n",
      "Overall, the code is efficient and adheres closely to the outlined requirements. It is ready for execution with minor improvements suggested for robustness.\n",
      "\n",
      "### Execution Instructions\n",
      "To execute the code:\n",
      "1. Ensure that the Python environment has the required packages `requests` and `beautifulsoup4` installed.\n",
      "2. Run the provided code snippet in your Python environment.\n",
      "\n",
      "### Complete Code\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Step 1: Download the HTML page of the given URL\n",
      "url = \"https://www.flipkart.com/\"\n",
      "response = requests.get(url)\n",
      "\n",
      "# Check if the request was successful\n",
      "if response.status_code == 200:\n",
      "    html_content = response.text\n",
      "    \n",
      "    # Step 2: Remove CSS, JavaScript, and Image content\n",
      "    soup = BeautifulSoup(html_content, 'html.parser')\n",
      "    \n",
      "    # Remove all style and script tags\n",
      "    for script in soup(['script', 'style', 'img']):\n",
      "        script.decompose()\n",
      "    \n",
      "    # Get text content\n",
      "    text_content = soup.get_text(separator='\\n', strip=True)\n",
      "    \n",
      "    # Step 3: Save the remaining HTML content to a file\n",
      "    with open('flipkart_text_content.txt', 'w', encoding='utf-8') as file:\n",
      "        file.write(text_content)\n",
      "\n",
      "    print(\"Content saved to 'flipkart_text_content.txt'\")\n",
      "else:\n",
      "    print(\"Failed to retrieve the webpage.\")\n",
      "```\n",
      "\n",
      "Once the code is executed, it will follow the prescribed steps, and the user will be informed when the content has been successfully saved. \n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as local_executor_agent. Provide feedback to CodeReviewer. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "\u001b[33mlocal_executor_agent\u001b[0m (to CodeReviewer):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: Content saved to 'flipkart_text_content.txt'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeReviewer\u001b[0m (to local_executor_agent):\n",
      "\n",
      "The code executed successfully, and the output confirms that the content has been saved to 'flipkart_text_content.txt'. If you have any further tasks or questions, feel free to ask. \n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as local_executor_agent. Provide feedback to CodeReviewer. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  exit\n"
     ]
    }
   ],
   "source": [
    "chat_results = autogen.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"sender\": user_proxy,\n",
    "            \"recipient\": code_writer_agent,\n",
    "            \"message\": messages[0],\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"sender\": local_executor_agent,\n",
    "            \"recipient\": code_reviewer_agent,\n",
    "            \"message\": messages[0] + messages[1],\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f188c31-3df1-46e3-831c-80fbdb29940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flipkart_text_content.txt', 'tmp_code_2ac7f8b83fd3d3594472c0a4b4e93d8d.py']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./code files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9356644-ad14-45e0-add4-a523b85ab1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
