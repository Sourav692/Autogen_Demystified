{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e3bcc1-f2dd-4b82-9a1f-486869cbd501",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "- **Role**: Strategist at a leading e-commerce company.\n",
    "- **Task**: Prepare for the upcoming festive season by analyzing competitors' discounts and promotional offers.\n",
    "- **Objective**: Design a competitive strategy to either match or surpass the competition's offers.\n",
    "\n",
    "## What You Will Build\n",
    "An **Agentic System** that can:\n",
    "- **Dynamically code** to handle changing website structures.\n",
    "- **Scrape the web** to extract discounts and promotional offers.\n",
    "- **Summarize data** into actionable insights for decision-making.\n",
    "\n",
    "## Learning Outcomes\n",
    "By the end of this notebook, you should be able to:\n",
    "- Configure AutoGen agents with and without LLMs.\n",
    "- Run local code execution safely in a controlled directory.\n",
    "- Orchestrate a multi-agent workflow (writer → reviewer → executor).\n",
    "\n",
    "## Outcome\n",
    "Enable data-driven decision-making to maintain a competitive edge during the festive season.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57bf01-3307-42c0-b117-fdcc4a04ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os\n",
    "from IPython import get_ipython\n",
    "from autogen import ConversableAgent, AssistantAgent, UserProxyAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Core imports:\n",
    "# - autogen: multi-agent orchestration framework\n",
    "# - LocalCommandLineCodeExecutor: runs code safely in a local working folder\n",
    "# - IPython display utilities: useful for rich notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781680b-fa3b-416e-8e41-4f3afa96e394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (e.g., API keys) from a .env file.\n",
    "# If your .env lives elsewhere, pass an explicit path to load_dotenv(\"/path/to/.env\").\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb6d90-eef7-4eb6-8d78-bc87c6eacc25",
   "metadata": {},
   "source": [
    "# Local Code Execution\n",
    "In this section, we create a local executor and connect it to an agent so that any generated code runs in a controlled folder with a time limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "698f3cdc-267b-4b91-9567-66138f00727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    # Disable LLM use for this agent (acts as a controller/user).\n",
    "    llm_config=False,\n",
    "    # Stop the conversation when a message contains the word TERMINATE.\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    # Only request human input when termination is reached.\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    # This agent does not execute code directly.\n",
    "    code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f49869-3d67-4275-8361-b5edf9f2bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_writer_agent = ConversableAgent(\n",
    "    name=\"CodeWriter\",\n",
    "    # System prompt guides the agent's behavior and stop condition.\n",
    "    system_message=\"\"\"You are a Python developer.\n",
    "    You use your coding skill to solve problems.\n",
    "    Once the task is done, returns 'TERMINATE'.\"\"\",\n",
    "    # Use a lightweight model for fast code generation.\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\"}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64cf50c8-df98-4cfa-84f2-1f030a03b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_reviewer_agent = ConversableAgent(\n",
    "    name=\"CodeReviewer\",\n",
    "    # Reviewer checks the generated code against requirements.\n",
    "    system_message=\"\"\"You are an experienced software developer\n",
    "    Review the code given to you based on the requirements\n",
    "    Once the task is done, returns 'TERMINATE'.\"\"\",\n",
    "    # Same model as writer for consistency.\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\"}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74cce19a-ce20-4b49-ac3f-250cc076d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_executor = LocalCommandLineCodeExecutor(\n",
    "    # Safety: limit execution time (seconds) for any generated script.\n",
    "    timeout=20,\n",
    "    # All generated files will be created inside this working directory.\n",
    "    work_dir='./code files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d37b009-74e7-499b-b382-de1a731aaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_executor_agent = ConversableAgent(\n",
    "    \"local_executor_agent\",\n",
    "    # No LLM here; this agent only runs code on the local machine.\n",
    "    llm_config=False, \n",
    "    # Attach the local executor for running generated scripts.\n",
    "    code_execution_config={\"executor\": local_executor},\n",
    "    # ALWAYS means the notebook may prompt for confirmation.\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8b31f1-3140-448e-860b-5fc2a0ec2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-step instruction set:\n",
    "# 1) ask the writer to generate code\n",
    "# 2) ask the reviewer to check it before execution\n",
    "messages = [\"\"\"To check whether there are any offers or discounts available on a given e-commerce website -\n",
    "                https://www.flipkart.com/\n",
    "                Follow these steps,\n",
    "                1. download the html page of the given URL\n",
    "                2. we only need text content, so remove any CSS, JavaScript, and Image content\n",
    "                3. save the remaining html content.\n",
    "               \"\"\" ,\n",
    "    \"\"\"The code is given by an LLM. Review the code based on the above requirements and provide it for execution\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df70c456-ab38-4885-a5fb-60499bfea323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to CodeWriter):\n",
      "\n",
      "To check whether there are any offers or discounts available on a given e-commerce website -\n",
      "                https://www.flipkart.com/\n",
      "                Follow these steps,\n",
      "                1. download the html page of the given URL\n",
      "                2. we only need text content, so remove any CSS, JavaScript, and Image content\n",
      "                3. save the remaining html content.\n",
      "               \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeWriter\u001b[0m (to User):\n",
      "\n",
      "To achieve the specified task, we can use Python with the `requests` library to download the HTML content and the `BeautifulSoup` library from `bs4` to parse the HTML and remove unwanted elements such as CSS, JavaScript, and images.\n",
      "\n",
      "Here's a step-by-step outline of the code:\n",
      "\n",
      "1. Download the HTML page from the given URL.\n",
      "2. Parse the HTML to remove unwanted elements.\n",
      "3. Save the cleaned HTML content to a file.\n",
      "\n",
      "You can run the following Python script to accomplish this.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Step 1: Download the HTML page\n",
      "url = \"https://www.flipkart.com/\"\n",
      "response = requests.get(url)\n",
      "\n",
      "# Step 2: Create a BeautifulSoup object and remove unwanted content\n",
      "soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "# Remove CSS and JavaScript\n",
      "for script in soup(['script', 'style']):\n",
      "    script.decompose()\n",
      "\n",
      "# Remove images\n",
      "for img in soup.find_all('img'):\n",
      "    img.decompose()\n",
      "\n",
      "# Get the text content\n",
      "cleaned_content = soup.get_text(separator='\\n')\n",
      "\n",
      "# Step 3: Save the cleaned content to a file\n",
      "with open('cleaned_flipkart_content.html', 'w', encoding='utf-8') as file:\n",
      "    file.write(cleaned_content)\n",
      "\n",
      "print(\"HTML content cleaned and saved.\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- `requests.get(url)`: Fetches the HTML content from the specified URL.\n",
      "- `BeautifulSoup(response.content, 'html.parser')`: Parses the HTML content.\n",
      "- `soup.decompose()`: Removes the specified tags from the soup object (including `<script>`, `<style>`, and `<img>`).\n",
      "- `soup.get_text(separator='\\n')`: Extracts text content from the parsed HTML.\n",
      "- Finally, the script saves the cleaned HTML content to a file named `cleaned_flipkart_content.html`.\n",
      "\n",
      "Remember to have `requests` and `beautifulsoup4` installed in your Python environment. You can install them using pip if necessary:\n",
      "\n",
      "```bash\n",
      "pip install requests beautifulsoup4\n",
      "```\n",
      "\n",
      "After running the script, you'll find the cleaned HTML content saved in the specified file.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (80f1e4c6-1f2b-4a02-844a-7db91306fe73): Termination message condition on agent 'User' met and no human input provided\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mlocal_executor_agent\u001b[0m (to CodeReviewer):\n",
      "\n",
      "To check whether there are any offers or discounts available on a given e-commerce website -\n",
      "                https://www.flipkart.com/\n",
      "                Follow these steps,\n",
      "                1. download the html page of the given URL\n",
      "                2. we only need text content, so remove any CSS, JavaScript, and Image content\n",
      "                3. save the remaining html content.\n",
      "               The code is given by an LLM. Review the code based on the above requirements and provide it for execution\n",
      "Context: \n",
      "To achieve the specified task, we can use Python with the `requests` library to download the HTML content and the `BeautifulSoup` library from `bs4` to parse the HTML and remove unwanted elements such as CSS, JavaScript, and images.\n",
      "\n",
      "Here's a step-by-step outline of the code:\n",
      "\n",
      "1. Download the HTML page from the given URL.\n",
      "2. Parse the HTML to remove unwanted elements.\n",
      "3. Save the cleaned HTML content to a file.\n",
      "\n",
      "You can run the following Python script to accomplish this.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Step 1: Download the HTML page\n",
      "url = \"https://www.flipkart.com/\"\n",
      "response = requests.get(url)\n",
      "\n",
      "# Step 2: Create a BeautifulSoup object and remove unwanted content\n",
      "soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "# Remove CSS and JavaScript\n",
      "for script in soup(['script', 'style']):\n",
      "    script.decompose()\n",
      "\n",
      "# Remove images\n",
      "for img in soup.find_all('img'):\n",
      "    img.decompose()\n",
      "\n",
      "# Get the text content\n",
      "cleaned_content = soup.get_text(separator='\\n')\n",
      "\n",
      "# Step 3: Save the cleaned content to a file\n",
      "with open('cleaned_flipkart_content.html', 'w', encoding='utf-8') as file:\n",
      "    file.write(cleaned_content)\n",
      "\n",
      "print(\"HTML content cleaned and saved.\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- `requests.get(url)`: Fetches the HTML content from the specified URL.\n",
      "- `BeautifulSoup(response.content, 'html.parser')`: Parses the HTML content.\n",
      "- `soup.decompose()`: Removes the specified tags from the soup object (including `<script>`, `<style>`, and `<img>`).\n",
      "- `soup.get_text(separator='\\n')`: Extracts text content from the parsed HTML.\n",
      "- Finally, the script saves the cleaned HTML content to a file named `cleaned_flipkart_content.html`.\n",
      "\n",
      "Remember to have `requests` and `beautifulsoup4` installed in your Python environment. You can install them using pip if necessary:\n",
      "\n",
      "```bash\n",
      "pip install requests beautifulsoup4\n",
      "```\n",
      "\n",
      "After running the script, you'll find the cleaned HTML content saved in the specified file.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeReviewer\u001b[0m (to local_executor_agent):\n",
      "\n",
      "The provided code is a well-structured approach to achieve the outlined requirements. Here's a review of each component:\n",
      "\n",
      "1. **Downloading the HTML Page**: \n",
      "   - The code correctly uses the `requests` library to get the HTML content from the specified URL, which is a fundamental first step.\n",
      "\n",
      "2. **Parsing HTML with BeautifulSoup**: \n",
      "   - It uses `BeautifulSoup` to parse the HTML content, which is efficient for manipulating and searching through HTML.\n",
      "\n",
      "3. **Removing Unwanted Content**: \n",
      "   - The approach to remove `<script>`, `<style>`, and `<img>` tags is correctly implemented using `decompose()`, which ensures that these elements do not remain in the final output.\n",
      "   - It is good that CSS and JavaScript are removed since they are not needed for textual content.\n",
      "\n",
      "4. **Extracting Text Content**: \n",
      "   - The extraction of text content using `get_text(separator='\\n')` is appropriate as it maintains the readability of the text by separating it with new lines.\n",
      "\n",
      "5. **Saving Cleaned Content**:\n",
      "   - The saved file is correctly written in UTF-8 encoding, which is essential for properly storing text from various character sets.\n",
      "\n",
      "### Additional Considerations:\n",
      "- The code does not handle exceptions (e.g., network issues, HTTP errors), which could be useful to add for robustness.\n",
      "- Consider adding a check for a successful response status (`response.status_code`) before proceeding to parse the HTML.\n",
      "- It might be useful to clear out any other potential tags that could contain unwanted content.\n",
      "\n",
      "Overall, the code meets the requirements well and follows good practices. Here is the final reviewed code:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "# Step 1: Download the HTML page\n",
      "url = \"https://www.flipkart.com/\"\n",
      "response = requests.get(url)\n",
      "\n",
      "# Check if the request was successful\n",
      "if response.status_code == 200:\n",
      "    # Step 2: Create a BeautifulSoup object and remove unwanted content\n",
      "    soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "    # Remove CSS and JavaScript\n",
      "    for script in soup(['script', 'style']):\n",
      "        script.decompose()\n",
      "\n",
      "    # Remove images\n",
      "    for img in soup.find_all('img'):\n",
      "        img.decompose()\n",
      "\n",
      "    # Get the text content\n",
      "    cleaned_content = soup.get_text(separator='\\n')\n",
      "\n",
      "    # Step 3: Save the cleaned content to a file\n",
      "    with open('cleaned_flipkart_content.html', 'w', encoding='utf-8') as file:\n",
      "        file.write(cleaned_content)\n",
      "\n",
      "    print(\"HTML content cleaned and saved.\")\n",
      "else:\n",
      "    print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
      "```\n",
      "\n",
      "Make sure to have the necessary libraries installed before running the script. This integrates error handling for improved robustness.\n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\u001b[0m\n",
      "\u001b[33mlocal_executor_agent\u001b[0m (to CodeReviewer):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: HTML content cleaned and saved.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeReviewer\u001b[0m (to local_executor_agent):\n",
      "\n",
      "The execution of the code was successful, and the cleaned HTML content has been saved as intended. If you have any further tasks or questions, feel free to ask! \n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mlocal_executor_agent\u001b[0m (to CodeReviewer):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeReviewer\u001b[0m (to local_executor_agent):\n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mlocal_executor_agent\u001b[0m (to CodeReviewer):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mCodeReviewer\u001b[0m (to local_executor_agent):\n",
      "\n",
      "TERMINATE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> TERMINATING RUN (7f9b339d-7a62-4155-bc5f-1540ebbd88cc): User requested to end the conversation\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run two sequential chats:\n",
    "# - User → CodeWriter (generate code)\n",
    "# - Local executor agent → CodeReviewer (review before execution)\n",
    "chat_results = autogen.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"sender\": user_proxy,\n",
    "            \"recipient\": code_writer_agent,\n",
    "            \"message\": messages[0],\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"sender\": local_executor_agent,\n",
    "            \"recipient\": code_reviewer_agent,\n",
    "            \"message\": messages[0] + messages[1],\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f188c31-3df1-46e3-831c-80fbdb29940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tmp_code_bf2ed78c30d35d8dee08d27be3c7ec79.py',\n",
       " 'cleaned_flipkart_content.html']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the artifacts generated by the local executor.\n",
    "os.listdir('./code files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd6a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Weekly Workout Schedule\n",
       "\n",
       "#### Monday\n",
       "- **Activity:** Full Body Strength Training\n",
       "- **Duration:** 45 minutes\n",
       "- **Focus:** Compound movements (squats, deadlifts, bench press, rows)\n",
       "\n",
       "#### Tuesday\n",
       "- **Activity:** Cardio (Running or Cycling)\n",
       "- **Duration:** 30 minutes\n",
       "- **Intensity:** Moderate pace\n",
       "\n",
       "#### Wednesday\n",
       "- **Activity:** Rest Day\n",
       "- **Focus:** Recovery and light stretching\n",
       "\n",
       "#### Thursday\n",
       "- **Activity:** Upper Body Strength Training\n",
       "- **Duration:** 45 minutes\n",
       "- **Focus:** Push-ups, pull-ups, shoulder press, bicep curls, tricep dips\n",
       "\n",
       "#### Friday\n",
       "- **Activity:** Cardio (HIIT Workout)\n",
       "- **Duration:** 30 minutes\n",
       "- **Intensity:** High-intensity intervals (30 seconds work, 30 seconds rest)\n",
       "\n",
       "#### Saturday\n",
       "- **Activity:** Lower Body Strength Training\n",
       "- **Duration:** 45 minutes\n",
       "- **Focus:** Lunges, leg press, calf raises, glute bridges\n",
       "\n",
       "#### Sunday\n",
       "- **Activity:** Rest Day\n",
       "- **Focus:** Recovery, yoga, or light walking\n",
       "\n",
       "### Notes:\n",
       "- Ensure to warm up before and cool down after each workout.\n",
       "- Stay hydrated and listen to your body; adjust intensity as needed.\n",
       "- Aim for at least 150 minutes of moderate aerobic activity throughout the week.\n",
       "\n",
       "."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c15d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
